Compute_Device:
  available:
  - cpu
  database_creation: cpu
  database_query: cpu
  gpu_brand: 
EMBEDDING_MODEL_NAME:
Platform_Info:
  os: windows
Supported_CTranslate2_Quantizations:
  CPU:
  - float32
  - int8_float32
  - int8
  GPU:
  - float32
  - float16
  - bfloat16
  - int8_float32
  - int8_float16
  - int8_bfloat16
  - int8
bark:
  enable_cpu_offload: false
  model_precision: float16
  size: normal
  speaker: v2/en_speaker_6
  use_better_transformer: true
database:
  chunk_overlap: 200
  chunk_size: 800
  contexts: 6
  similarity: 0.9
embedding-models:
  bge:
    query_instruction: 'Represent this sentence for searching relevant passages:'
  instructor:
    embed_instruction: 'Represent the document for retrieval:'
    query_instruction: 'Represent the question for retrieving supporting documents:'
server:
  api_key: ''
  connection_str: http://localhost:1234/v1
  model_max_tokens: -1
  model_temperature: 0.1
  prefix: '### User:'
  prefix_chat_ml: <|im_start|>
  prefix_llama2_and_mistral: '[INST]'
  prefix_llava_13B: '### Instruction:\\n'
  prefix_neural_chat: '### User:'
  prefix_obsidian_3B: <|im_start|>user\n
  prefix_orca2: <|im_start|>user
  prefix_phi2: 'Instruct:'
  prompt_format_disabled: false
  suffix: '### Assistant:'
  suffix_chat_ml: <|im_end|>
  suffix_llama2_and_mistral: '[/INST]'
  suffix_llava_13B: \\n### Response:\\n
  suffix_neural_chat: '### Assistant:'
  suffix_obsidian_3B: '\n###\n<|im_start|>assistant:'
  suffix_orca2: <|im_end|><|im_start|>assistant
  suffix_phi2: 'Output:'
styles:
  button: 'background-color: #323842; color: light gray; font: 10pt "Segoe UI Historic";
    width: 29;'
  frame: 'background-color: #161b22;'
  input: 'background-color: #2e333b; color: light gray; font: 13pt "Segoe UI Historic";'
  text: 'background-color: #092327; color: light gray; font: 12pt "Segoe UI Historic";'
test_embeddings: false
transcribe_file:
  device: cpu
  file: null
  model: large-v2
  quant: float16
  timestamps: true
transcriber:
  device: cpu
  model: small.en
  quant: float32
vision:
  bakllava:
    available_quants:
    - 4-bit
    - 8-bit
    - float16
    available_sizes:
    - 7b
  batch: null
  chosen_model: llava
  chosen_quant: 4-bit
  chosen_size: 7b
  cogvlm:
    available_quants:
    - 4-bit
    - 8-bit
    available_sizes:
    - 18b
  flash_attention2: null
  llava:
    available_quants:
    - 4-bit
    - 8-bit
    - float16
    available_sizes:
    - 7b
    - 13b
  test_image: null

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embedding Models</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}
		
		h2:target {
			padding-top: 200px;
			margin-top: -100px;
			display: block;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000;
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Embedding Models</h1>
		<nav>
			<a href="#overview">Overview</a> |
			<a href="#model">Choosing the Correct Model</a> |
			<a href="#semantic">Semantic Search</a> |
			<a href="#clustering">Clustering or Semantic Search</a> |
			<a href="#sentence_similarity">Sentence Similarity</a> |
			<a href="#rounded">Well Rounded</a> |
			<a href="#dimensions">Max Sequence and Dimensions</a> |
			<a href="#total_context">Total Program Context</a>
		</nav>
	</header>
	
	<main>
	
	<h2 id="overview">Overview</h2>
	
	<p>My program loads an embedding model into memory for:
<ol>
    <li>Creating the vector database</li>
    <li>Querying the vector database before your question and the "context" it obtains are sent to the LLM for an answer.</li>
</ol>
	
	<p><b>To get the most out of this program, it's crucial to choose the right embedding model.  Remember, the LLM's
	response is only as good as the context you provide via the embedding model.</b></p>

	<h2 id="model">Choosing the Correct Model</h2>
	
	<p>The first rule of embedding models is experiment.  Make sure and review the list of models displayed when you click
	"Download Model".  These instructions directly relate to the information displayed there. With that being said, there
	is no one-size-fits-all .  However, based my research and testing the following rules apply:</p>
	
	<h2 id="semantic">Semantic Search</h2>
	
	<p>Semantic search generally refers to obtaining results that are similar to your query  This includes RAG and other
	tasks, but this program is geared towards RAG.  All of the embedding models with the "Semantic search" description
	will perform reasonably well for this with a few nuances.</p>
	
	<p>Models with <code>msmarco</code> in their name are specifically trained to provide longer results when
	given a short question:</p>
	
	<p><b>Tell me everything that this legal treatise say about the elements of a defamation claim?</b></p>
	<p><b>What are all the kinds of troubles that the main character from the book experiences?</b></p>
	
	<p>This is called "asymmetric semantic search.  Other models with the "Semantic search" description are GENERALLY
	"symmetric semantic search," which means that they tend to produce results of the same length of your question.</p>
	
	<p>In addition, models with <code>multi-qa</code> in their name have specifically been trained on question answering
	and are similar in function to <code>msmarco</code> models.  You'll just have to experiment with the different
	models as well as how you structure your query.</p>
	
	<p>With that being said, more recent larger models like ones beginning with <code>gtr</code> (to give one example)
	claim to be just as efficient as "specialist" models.  The recent trend has been for larger models good at everything.</p>
	
	<h2 id="clustering">Clustering or Semantic Search</h2>
	
	<p>Models with the description of "clustering or semantic search" basically means "well rounded."  They are good at
	question answering as well as other tasks, but for purposes of this program you should think of them as "well rounded."</p>
	
	<p>The <code>all-mpnet-base-v2</code> model is widely considered the best of its size in this category, and some claim
	that it performs better than models in the "Semantic Search" category, for example.	And as previously stated, the larger
	models might outperform, or vice versa.  Just experiment.</p>
	
	<h2 id="sentence_similarity">Sentence Similarity</h2>
	
	<p>There are onlyk three models with this description.  They focus on providing sentences that are very similar to
	your question/sentence as possible; for example:</p>
	
	<p><b>Quote for me all sentences that discuss the main character in this book eating food</b></p>
	<p><b>Provide me all sentences verbatim of a court discussing the elements of a defamation claim.</b></p>
	
	<p>The search results should be multiple chunks with highly relevant sentences (as opposed to answering a question):</p>
	
	<h2 id="rounded">Well Rounded</h2>
	
	<p>Self-explanatory.  But again, the larger models sometimes perform just as good as the specialist models.</p>
	
	<p>The "customizable" description means that you can modify an "instruction" parameter when running the model.  However, I
	removed this setting from the Settings tab to conserve space since I never saw the need based off of my searched.  If you
	want to add it back, feel free to modify <code>gui_tabs_settings_models.py</code> to make the setting visible again.
	Only the <code>instructor</code> and <code>bge</code> models use this parameter.</p>
	
	<h2 id="dimensions">Max Sequence and Dimensions</h2>
	
	<p>The "max sequence" of an refers to the maximum number of tokens (not characters) that it can process at once.
	A model's "dimensions" refers to how nuanced a meaning it can extract from text.  A higher "dimensions" means that
	the model can discern nuanced meanings from very similar text and provide more accurate results.</p>
	
	<p>The "max sequence" of a model relates to the "chunk size" setting within the Settings tab. "Chunk size" means
	that the program strives to chunk text to the specified number of characters (not tokens), and then
	these chunks are sent to the embedding model.  Therefore, it's important to make sure that chunk size
	(in characters) doesn't exceed a model's "max sequence" (in tokens).  To analyze this, a general rule of thumb
	is that a token approximately consists of four (4) characters.  If you set the chunk size to 1200, for example,
	you would need to make sure the embedding model you're using has a max sequence length of 300+.</p>
	
	<p>If the chunks are too large, the embedding model will simply truncate them, but this will make your search
	less accurate.</p>
	
	<h2 id="total_context">Total Program Context</h2>
	
	<p>Finally, remember to abide by the total context (in tokens) available from the LLM within LM Studio (typically 4096).
	The program prints in the command prompt the total number of tokens received from the embedding model and sent to
	the LLM within LM Studio.  To calculate how many tokens the LLM cand respond with, you would subtract the total number
	of tokens sent to LM Studio from 4096.  For example, if 3096 tokens are sent to LM Studio, the LLM within LM
	Studio would have 1000 tokens to respond (approximately 4,000 characters).</p>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

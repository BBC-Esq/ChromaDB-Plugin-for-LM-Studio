<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embedding Models</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000;
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Embedding Models</h1>
	</header>
	
	<main>
	
	<h2>Overview</h2>
	
	<p>My program loads an embedding model into memory for:
<ol>
    <li>Creating the vector database</li>
    <li>Querying the vector database before your question and the "context" it obtains are sent to the LLM for an answer.</li>
</ol>
	
	<p><b>To get the most out of this program, it's crucial to choose the right embedding model.  Remember, the LLM's
	response is only as good as the context you provide it via the embedding model, but it's also helpful to
	understand a little background.</b></p>
	
	<p>"Embeddings" are also referred to as "vectors" and are essentially numbers representing the meaning of words.  i
	use these terms interchangeably herein.  A vector model simply converts text to numbers.</p>
	
	<p>This program extracts the text from a variety of file formats, chunks the text, and then feeds the chunks to
	the vector model for processing.  Images are first processed by the selected "vision" models, which create a
	text description of the image, and then this text is processed.  Audio files must first be transcribed in the
	"Tools" tab, but again, once the transcription is done the text is fed to the vector model once you actually
	create the vector database.</p>

	<h2>Choosing the Correct Model</h2>
	
	<p>The first rule of embedding models is experiment.  You can review the characteristics of the embedding models
	from the "Models" tab.</p>
	
	<h2>Categories</h2>
	
	<p>The vector models are categories by the company that made them.  All categories are populated with large
	all-encompassing models that don't specialize in one particular task except the "Sentence Transformers"
	category (explained below).  If you find a model that this program doesn't support feel free to create an
	issue on Github requesting a specific model.</p>
	
	<h2>Sentence Transformers Models</h2>
	
	<p>The "Sentence Transformers" organization is the most well-known company that's created vector models.
	The models with "sentence" in their name are unique in that they focus on returning results consisting
	of sentences most similar to the sentence you pose as a question; for example:</p>
	
	<p><b>Quote for me all sentences that discuss the main character in this book eating food.</b></p>
	<p><b>Provide me all sentences verbatim of a court discussing the elements of a defamation claim.</b></p>
	
	<p>The search results should be multiple chunks with highly relevant sentences.  There are four such
	models.  Be careful when using the "xxl" variant, however, since it requires more than 24 GB of VRAM/RAM.</p>
	
	<h2>Other Models</h2>
	
	<p>All other vector models - whethe from the sentence-transformers organization or otherwise - are good
	all-purpose well-rounded models suitable for RAG.  The "all-mpnet-base-v2" model is widely regarded
	as the best for its size and resource requiremnts, but feel free to experiment with the others as well.</p>
	
	<h2>Model Characteristics</h2>
	
	<p><code>Max Sequence</code> refers to the maximum number of <code>tokens</code> (not characters) that a Model
	can process in one pass.  Make sure that the chunks you create are do not exceed the "max sequence"
	of the embedding model you create the vector database with.  Also, remember that the "chunk" size setting
	is in "characters" and not "tokens."  A good rul of thumb is that there are four (4) characters on average
	in each chunk.</p>
	
	<p><code>"Dimensions"</code> basically refers to the complexity that the vector model can create when converting
	text into vectors (aka numbers).  A higher number means that the vector model can discern more nuance in
	text; hence, more accurate search results.</p>
	
	<p><code>Size</code> refers to the size of the vector model on your computer.</p>
	
	<h2>Tips</h2>
	
	<p>The model you choose to run in LM Studio has a maximum context length as all models do, which is in
	tokens. Most mainstream models nowadays have a maximum context of 4096 tokens.</p>
	
	<p>After choosing a good vector model and ensuring that the chunks don't exceed the "max sequence" for
	a particular model, the best way to improve search results is to craft a good question.  With some practice
	you should get the ansdwer to your question in the first 1-4 chunks obtained from the vector database.
	If you don't it likely means that you need to revise your question, revisit your chunk size and overlap
	settings or choose a more appropriate vector model.</p>
	
	<p>Test the chunk size and overlap settings by checking the "chunks only" checkbox near the "Submit
	Question" button.  This will force the program to only return the chunks and no longer connect to
	LM Studio.  This is great because you can visually see what's actually in the database.</p>
	
	<p>Another use case is creating a vector database of only images (or only searching images).  You may want any and all image
	chunks that relate to a certain topic.  You can use the "chunks only" checkbox and set the "contexts" to 1000+ for this.</p>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

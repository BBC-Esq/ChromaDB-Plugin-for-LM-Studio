<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embedding Models</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000;
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Embedding Models</h1>
	</header>
	
	<main>
	
	<h2>Overview</h2>
	
	<p> This program basically extracts text from a variety of file formats and converts the chunks into vectors.
	"Vectors" - aka "embeddings" - represent the meaning of the chunk of text.  <code>TileDB</code> then creates a
	vector database out of the the chunks of text and their corresponding vectors.  This database can then be
	searched by converting a user's question into a vector and comparing how similar it is to the vectors
	within the database.  The most relevant text chunks are then returned.  This entire process is commonly
	referred to as "retrieval augmented generation" or "RAG".</p>

	<h2>Choosing the Correct Model</h2>
	
	<p>Different vector models have  difference characteristics so it's important to choose the correct one for
	the task at hand.  You can view their characteristics from the <code>Models Tab</code>.
	
	<h2>Categories</h2>
	
	<p>In general, the vector models are displayed in categories based on the company that made them.
	All of the models are well-rounded all-purpose models except for a few models within the
	<code>sentence-transformers</code> category.  Feel free to experiment with different models
	and sizes.  There is no definitive "best" model.</p>
	
	<h2>Sentence Transformers Models</h2>
	
	<p><code>all-MiniLM-L6-v2</code>, <code>all-MiniLM-L12-v2</code>, and <code>all-mpnet-base-v2</code>
	are well-rounded all-purpose vector models.  <code>all-mpnet-base-v2</code> is typically considered
	the best model for its size across all companies.</p>
	
	<p>The <code>msmarco</code> was specifically trained on question/answer data and returning multiple
	relevant passages from a short question.  However, it is arguablly eclipsed by the larger all-purpose
	models.  You'll just have to experiment to determine which is the best for your use-case.</p>
	
	<p>Models with <code>sentence-t5</code> in their name are unique in that they are specifically
	trained to return similar sentences.  They should not be used if you use large chunks of text
	beyond the typical size of a sentence.  These models perform extremely well for locating sentences
	that are similar to a sentence that a user specifies.  In other words, you should not pose a
	question but rather simply state a sentence and the model will return sentences that have as close
	a meaning as possible.</p>
	
	<p>For example:</p>
	
	<p><b>Quote for me all sentences that discuss the main character in this book eating food.</b></p>
	
	<p>or...</p>
	
	<p><b>Provide me all sentences verbatim of a court discussing the elements of a defamation claim.</b></p>
	
	<p>NOTE: You should not use the "xxl" version of this model unless you have a GPU with 24 GB of VRAM.
	The resource requirements of this model are the highest out of any model this program uses.</p>
	
	<h2>Characteristics Common to All Models</h2>
	
	<p>All models share some basic characteristics depending on their architecture and training.</p>
	
	<p>The <code>max sequence</code> of a model refers to the maximum number of <code>tokens</code>
	(not characters) that a Model can process at a time.  The "chunk size" setting allows you to specify
	size of text chunks that you want converted into vectors.  However, this is in "characters" (not
	tokens).  A token is approximately four characters.  Therefore, make sure that the "chunk size setting
	is no more than approximately 4x the <code>max_sequence</code> of the vector model you intend to use.
	If your chunks are too large they will simply be truncated, harming your search results.</p>
	
	<p>A vector model's<code>"dimensions"</code> refers to how much nuance in meaning that the model can
	discern from text.  A higher number means that it can discerng more meaning, thus improving search
	results.</p>
	
	<p>A vector model's<code>size</code> simply refers to its size on your computer of that's a factor for you.</p>
	
	<h2>Tips</h2>
	
	<p>Just like a vector model, the model you choose within LM Studio has a maximum context limit, which
	is essentically the same thing as the <code>max_sequence</code> for a vector model.  This program sends
	your question along with the relevant chunks obtained from the vector database to the LLM within LM
	Studio.  Therefore, you must ensure that what you send the LLM does not exceed this context limit.
	Most recent models have a context limit of 4096 tokens (not characters) but consult the model card
	if you're unsure.  But more importantly, you must leave enough context for the LLM's response as well.
	In other words, even if your question and the results are less than the LLM's context limit, you will
	not get a response if there is not enough left for the LLM to respond with.</p>
	
	<p>Experiment with different formulations of your question.  Ideally, you should get at least one chunk
	that is highly relevant in the top 3 chunks returned.  You can view the actual chunks as a test (without
	connecting to LM Studio) by using the "chunks only" checkbox near the search button.  If you don't get
	at least one highly-relevant chunk within the top three chunks returned, experiment with your question.</p>
	
	<p>Different chunk sizes produce better results based on the type of text being vectorized.  Experiment
	with different chunks sizes.  Likewisem, different "chunk overlap" settings can influence the search
	results.  A good rule of thumb is to set the "chunk overlap" to a third of your chunk size.</p>
	
	<p>This program can also use "vision" models to create a text description of one or more images, which
	are then put into the vector database.  These descriptions are usually 1-3 sentences.  Make sure and
	choose a "chunk size" that is at least this length because you do not want the description to be split
	into multiple chunks.  Usually this isn't a problem since 1-3 sentences is only approximately 50-150
	characters, but just something to be aware of.  If you have any doubt, use the "chunks only" checkbox.</p>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}
		
		h2:target {
			padding-top: 275px;
			margin-top: -100px;
			display: block;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000; /* for th and td */
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Whisper Transcription</h1>
	</header>
	
	<main>
	
	<h2>Overview</h2>
	
	<p><b>This program uses state-of-the-art Whisper models to:</b></p>
<ol>
    <li>Transcribe your question into the question box</li>
    <li>Transcribe an audio file to a <code>.txt</code> file that will be put into the vector database.</li>
</ol>

	<h2>Transcribe Question</h2>
	
	<p>The <code>Record Question</code> button starts the recording.  Speak and then click it gain to stop recording
	and your question will automatically be transcribed to the question box.  Currently the <code>small.en</code>
	whisper model is us by default but I plan on adding the ability to change the size and quantization in a future
	release.</p>
	
	<h2>Transcribe File</h2>
	
	<p>To add audio files to a vector database you do not select them en masse like other file types; you must
	transcribe them first.  Go to the "Tools Tab" and select a file to transcribe and the quality of the Whisper
	model to use.  It's recommended to use the highest quality Whisper model and quantization that you feel is
	"reasonable" based on your system hardware and the processing time required as a result.  This is because
	ideally you only transcribe the file once before it's put into the vector database and you want reliable search
	results.</p>
	
	<p>It's highly recommended to use gpu-acceleration within the "Settings Tab" when transcribing an audio file.
	If you're forced to use CPU the smallest model I recommend is <code>small-en</code> using a quantization
	of <code>float32</code></p>
	
	<p>Once the transcription is complete you will see it in the "Create Database" tab and it's ready to be put into
	the vector database.  Simply add any additional files/transcriptions and create the database.</p>

	<p>The <code>Speed</code> setting allows you to reduce the time it takes to transcribe a file at the cost of increased
	memory and compute requirements.  This setting essentially sets the number of "batches" sent to the Whisper model
	at once.  Thus, sending the a certain number of batches to the <code>whisper-large-v2</code> model will consume
	much more resources/compute than the same number of batches sent to the <code>small-en</code> model.  In general,
	a "Speed" setting of approximately 40 when using the <code>large-v2</code> model will still fit within the
	VRAM of an RTX 4090 whereas using the <code>tiny-en</code> allows a batch size of well over 125.  Experiment
	to find the fastest setting that does not exceed your avaialble VRAM.  If it exceeds your VRAM, the transcription
	process will be MUCH MUCH SLOWER.</p>
	
	<p>If you're not using gpu-acceleration obviously a much lower Speed setting is necessary.</p>
	
        <h2 id="floating">Primer on Floating Point Formats</h2>
		
		<section>
            <img src="./float.png" alt="Floating Point">
        </section>

        <p>Running an embedding model or an LLM requires a lot of math calculations and computers don't understand
		decimals (1,2,3) like humans.  Instead, they represent numbers with a series of ones and zeros called "bits."
		In general, the more bits used used to represent a number means higher accuracy when performing math calculations, which
		means a higher quality in a model's output.  However, this also means that more memory and compute resources are needed.</p>
		
		<p>The "quality" of a model also depends on how many of the bits are "exponent" versus "fraction." The phrase
		"<u>Floating Point Format</u>" refers to both (1) the total number of bits used and (2) how many of those bits are
		"exponent" versus "fraction" bits.  The three most common floating point formats are above.  Notice that both
		<u>float16</u> and <u>bfloat16</u> use 16 bits but a differing number of "exponent" versus "fraction" bits.</p>
		
		<p>The number of "<u>exponent</u>" bits determines the "range" of numbers that can be used when performing math calculations.
		For example, <u>float32</u> uses 8 "exponent" bits, which hypothetically allows using any integer between one and
		one-hundred.  Its "range," in other words, is 1-100.  <u>Bfloat16</u> would have the same "range" because it also
		uses 8 "exponent" bits.  However, <u>float16</u> might have a "range" of 1-50  since it only uses 5 "exponent" bits.</p>

        <p></p>
		
		<p>The number of "<u>fraction</u>" bits determines how many "<u>unique values</u>" that can be used within that "range."
		For example, <u>float32</u> uses 23 "fraction" bits, which hypothetically allows it to use every whole number between 1-100
		when doing math.  <u>Bfloat16</u> only uses 7 "fraction" bits, which hypothetically only allows it to use 25 unique values
		within its range.  This is sometimes referred to as the "precision" of floating point format.</p>

        <p>Hypotheticals aside, here are the actual ranges/precisions:</p>
		
			<table class="table-from-second-file" border="1">
				<tr>
					<th>Floating Point Format</th>
					<th>Range (Approximate)</th>
					<th>Precision</th>
				</tr>
				<tr>
					<td>float32</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>6 to 9 decimal digits</td>
				</tr>
				<tr>
					<td>float16</td>
					<td>±6.1 × 10<sup>-5</sup> to ±6.5 × 10<sup>4</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
				<tr>
					<td>bfloat16</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
			</table>

		<p>It's important to note that "<u>range</u>" and "<u>precision</u>" both determine the "quality" of an output but in
		different ways, and different floating point formats are good for different purposes.  For example, Google (which created
		<u>bfloat16</u>), found that it was better for neural networks while <u>float16</u> was better for "scientific" calculations.</p>
		
		<p>You can see the floating point format of the various embedding models used inthis program by looking at the
		<code>config.json</code> file for each model.  All of the Whisper models used in this program were created with
		<u>float32</u> and you can experiment with the various quantizations I've done for each size of model.</p>
		
        <section>
            <h2 id="quantization">What is Quantization?</h2>
			
            <p>"<u>Quantization</u>" means converting the original floating point format to one with a smaller "range" and/or "precision."
			Projects like <u>llama.cpp</u>, <u>AutoGPTQ</u>, and <u>Ctranslate2</u> each have their strengths and weaknesses, but the
			goal is to reduce the resources needed while only suffering a "reasonable" loss in quality.</p>
			
			<p>For example, descriptions such as "Q8_0" or "8-bit" refer to the "floating point format" of "<u>int8</u>," which has
			the following range and precision:
			
		<table class="table-from-second-file" border="1">
			<tr>
				<th>Integer Data Type</th>
				<th>Range</th>
				<th>Number of Discrete Values</th>
			</tr>
			<tr>
				<td>int8</td>
				<td>-128 to 127</td>
				<td>256 (from -128 to 127)</td>
			</tr>
		</table>

			<p><b>Technically</b>, "int8" is no longer "floating"...but this primer is not intended to explain things at a university
			level...</p>
			
			<p>...you might say that the "range" and/or "precision" of this primer is only what is necessary to give a user a
			basic understanding of the concepts in order to use this program.  In other words, I have specifically chosen to use
			a lower floating point format in order to avoid the memory and compute resources required to fully research all of
			the concepts discussed in this primer...after all, we're not sending astronauts into space here!</p>

	<h2 id="available-models">Whisper Sizes and Quants</h2>
	
	<table>
        <thead>
            <tr>
                <th>Quantization</th>
                <th>Size on Disk</th>
            </tr>
        </thead>
        <tbody>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_bfloat16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_bfloat16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float32</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float32</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_bfloat16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_bfloat16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-bfloat16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-bfloat16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float32</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float32</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-bfloat16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-bfloat16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float32</td>
                <td>154.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float32</td>
                <td>154.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_bfloat16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_bfloat16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float32</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float32</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float32</td>
                <td>293.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float32</td>
                <td>294.0 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-bfloat16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-bfloat16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_bfloat16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_bfloat16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float32</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float32</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float32</td>
                <td>970.4 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float32</td>
                <td>970.7 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_bfloat16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float32</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-bfloat16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float32</td>
                <td>6.2 GB</td>
            </tr>
        </tbody>
    </table>
</div>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

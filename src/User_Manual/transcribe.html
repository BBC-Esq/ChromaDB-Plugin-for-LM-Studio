<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}
		
		h2:target {
			padding-top: 275px;
			margin-top: -100px;
			display: block;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000; /* for th and td */
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Whisper Transcription</h1>
		<nav>
			<a href="#overview">Overview</a> |
			<a href="#transcribe-question">Transcribe Question</a> |
			<a href="#transcribe-file">Transcribe Audio Files</a> |
			<a href="#whisper-models">Whisper Models and Quants</a> |
			<a href="#additional-info">Additional Info</a> |
			<a href="#available-models">Available Whisper Models and Quants</a> |
			<a href="#floating">Introduction to Floating Point Formats</a> |
			<a href="#quantization">What is Quantization?</a>
		</nav>
	</header>
	
	<main>
	
	<h2 id="overview">Overview</h2>
	
	<p><b>This program uses state-of-the-art Whisper models in two ways:</b></p>
<ol>
    <li>Transcribe your question into the question box; and</li>
    <li>Transcribe an audio file to <code>.txt</code> to be put into the vector database.</li>
</ol>

	<h2 id="transcribe-question">Transcribe Question</h2>
	
	<p>The start and stop recording buttons allow you to transcribe your question for the LLM instead of typing it. The
	<code>Model</code>, <code>Quant</code>, and <code>Device</code> settings within the <u>Settings Tab</u> pertain to this
	functionality.  <code>Model</code> refers to the size of the Whisper model.  A larger model produces more accurate results but
	takes longer and requires more resources.  <code>Quant</code> refers to the quantization level, which is explained more below.
	<code>Device</code> refers to using CPU, GPU or MPS (for some Macs) when transcribing your question.</p>
	
	<p>When transcribing a question, I recommend using the <u>small/small.en</u> model, a quantization of <u>float32</u>, and CPU.
	Remember, you MUST click the <u>Update Settings</u> button to update these settings.</p>
	
	<h2 id="transcribe-file">Transcribe File</h2>
	
	<p>Within the <u>Tools Tab</u> you can choose an audio file (or a directory of audio files) to transcribe to a <code>.txt</code>
	file(s), which can subsequently put into the vector database.  The relevant settings are also within the Tools Tab.
	In contrast to transcribing a question, when transcribing a file I recommend using as large a Whisper model as possible,
	a quantization of no less than <u>float16/bfloat16</u> (preferably <u>float32</u>), and GPU or MPS.  When transcribing a short
	question it's easy to correct mistakes, but you don't want to sift through an hour-long transcript for mistakes.</p>
	
	<p>Eject the LLM from within LM Studio to free up VRAM, if need be, when transcribing a file.</p>
	
	<p>Note, the settings for transcribing a file are automatically updated and you don't need to click any button to update them.</p>
	
	<h2 id="whisper-models">Whisper Model Nuances</h2>
	
	<p>Whisper models ending in <code>.en</code> specialize in transcribing English.  The <code>large-v2</code> model doesn't have
	a <code>.en</code> variant because it's simply good at everything.  Currently, this program does not support translating a
	question into English nor translating an audio file into English; therefore, use Whisper models ending in <code>.en</code>.
	If/when translating a question or audio file is implemented, the non-<code>.en</code> models will become relevant.</p>
	
	<p>Pro tip.  The size of the model determines its quality followed next by its quantization.</p>
	
	<h2 id="additional-info">Transcription Times</h2>
	
	<p>The tables below generally show the memory requirements for the various sizes/quantizations and transcriptions times.
	Note, a lower quantization <u>ALWAYS</u> means less memory (and less quality) but <u>DOES NOT</u> mean less transcription time.
	The CUDA tests were done with an RTX 4090.  The CPU test was done with an 13900k using 28 out of 32 logical cores.
	The audio file itself was a <code>.flac</code> that was 2 hours and 24 minutes long.</p>
	
<style type="text/css">
#T_7a207_ td {
  background-color: #b3e0ff;
}
#T_7a207_ th {
  background-color: none;
}
#T_7a207_row0_col1, #T_7a207_row0_col3, #T_7a207_row1_col1, #T_7a207_row1_col3, #T_7a207_row2_col1, #T_7a207_row2_col3, #T_7a207_row3_col1, #T_7a207_row3_col3 {
  text-align: center;
}
</style>
<table id="T_7a207_">
  <thead>
    <tr>
      <th class="col_heading level0 col0" >Model</th>
      <th class="col_heading level0 col1" >Compute Platform</th>
      <th class="col_heading level0 col2" >Transcription Time</th>
      <th class="col_heading level0 col3" >Memory Used</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td id="T_7a207_row0_col0" class="data row0 col0" >Large v2 (float32)</td>
      <td id="T_7a207_row0_col1" class="data row0 col1" >CUDA</td>
      <td id="T_7a207_row0_col2" class="data row0 col2" >~8 min 25 sec</td>
      <td id="T_7a207_row0_col3" class="data row0 col3" >~7 GB VRAM</td>
    </tr>
    <tr>
      <td id="T_7a207_row1_col0" class="data row1 col0" >Large v2 (float16)</td>
      <td id="T_7a207_row1_col1" class="data row1 col1" >CUDA</td>
      <td id="T_7a207_row1_col2" class="data row1 col2" >~7 min 15 sec</td>
      <td id="T_7a207_row1_col3" class="data row1 col3" >~5 GB VRAM</td>
    </tr>
    <tr>
      <td id="T_7a207_row2_col0" class="data row2 col0" >Large v2 (int8)</td>
      <td id="T_7a207_row2_col1" class="data row2 col1" >CUDA</td>
      <td id="T_7a207_row2_col2" class="data row2 col2" >~12 min 25 sec</td>
      <td id="T_7a207_row2_col3" class="data row2 col3" >~3.1 GB VRAM</td>
    </tr>
    <tr>
      <td id="T_7a207_row3_col0" class="data row3 col0" >Large v2 (float32)</td>
      <td id="T_7a207_row3_col1" class="data row3 col1" >CPU</td>
      <td id="T_7a207_row3_col2" class="data row3 col2" >~103 min 30 sec</td>
      <td id="T_7a207_row3_col3" class="data row3 col3" >~7 GB RAM</td>
    </tr>
  </tbody>
</table>
	
	<h2 id="available-models">Whisper Sizes and Quants</h2>
	
	<table>
        <thead>
            <tr>
                <th>Quantization</th>
                <th>Size on Disk</th>
            </tr>
        </thead>
        <tbody>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_bfloat16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_bfloat16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float32</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float32</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_bfloat16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_bfloat16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-bfloat16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-bfloat16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float32</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float32</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-bfloat16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-bfloat16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float32</td>
                <td>154.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float32</td>
                <td>154.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_bfloat16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_bfloat16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float32</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float32</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float32</td>
                <td>293.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float32</td>
                <td>294.0 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-bfloat16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-bfloat16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_bfloat16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_bfloat16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float32</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float32</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float32</td>
                <td>970.4 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float32</td>
                <td>970.7 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_bfloat16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float32</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-bfloat16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float32</td>
                <td>6.2 GB</td>
            </tr>
        </tbody>
    </table>
</div>

        <h2 id="floating">Primer on Floating Point Formats</h2>
		
		<section>
            <img src="./float.png" alt="Floating Point">
        </section>

        <p>Running an embedding model or an LLM requires a lot of math calculations and computers don't understand
		decimals (1,2,3) like humans.  Instead, they represent numbers with a series of ones and zeros called "bits."
		In general, the more bits used used to represent a number means higher accuracy when performing math calculations, which
		means a higher quality in a model's output.  However, this also means that more memory and compute resources are needed.</p>
		
		<p>The "quality" of a model also depends on how many of the bits are "exponent" versus "fraction." The phrase
		"<u>Floating Point Format</u>" refers to both (1) the total number of bits used and (2) how many of those bits are
		"exponent" versus "fraction" bits.  The three most common floating point formats are above.  Notice that both
		<u>float16</u> and <u>bfloat16</u> use 16 bits but a differing number of "exponent" versus "fraction" bits.</p>
		
		<p>The number of "<u>exponent</u>" bits determines the "range" of numbers that can be used when performing math calculations.
		For example, <u>float32</u> uses 8 "exponent" bits, which hypothetically allows using any integer between one and
		one-hundred.  Its "range," in other words, is 1-100.  <u>Bfloat16</u> would have the same "range" because it also
		uses 8 "exponent" bits.  However, <u>float16</u> might have a "range" of 1-50  since it only uses 5 "exponent" bits.</p>

        <p></p>
		
		<p>The number of "<u>fraction</u>" bits determines how many "<u>unique values</u>" that can be used within that "range."
		For example, <u>float32</u> uses 23 "fraction" bits, which hypothetically allows it to use every whole number between 1-100
		when doing math.  <u>Bfloat16</u> only uses 7 "fraction" bits, which hypothetically only allows it to use 25 unique values
		within its range.  This is sometimes referred to as the "precision" of floating point format.</p>

        <p>Hypotheticals aside, here are the actual ranges/precisions:</p>
		
			<table class="table-from-second-file" border="1">
				<tr>
					<th>Floating Point Format</th>
					<th>Range (Approximate)</th>
					<th>Precision</th>
				</tr>
				<tr>
					<td>float32</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>6 to 9 decimal digits</td>
				</tr>
				<tr>
					<td>float16</td>
					<td>±6.1 × 10<sup>-5</sup> to ±6.5 × 10<sup>4</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
				<tr>
					<td>bfloat16</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
			</table>

		<p>It's important to note that "<u>range</u>" and "<u>precision</u>" both determine the "quality" of an output but in
		different ways, and different floating point formats are good for different purposes.  For example, Google (which created
		<u>bfloat16</u>), found that it was better for neural networks while <u>float16</u> was better for "scientific" calculations.</p>
		
		<p>You can see the floating point format of the various embedding models used inthis program by looking at the
		<code>config.json</code> file for each model.  All of the Whisper models used in this program were created with
		<u>float32</u> and you can experiment with the various quantizations I've done for each size of model.</p>
		
        <section>
            <h2 id="quantization">What is Quantization?</h2>
			
            <p>"<u>Quantization</u>" means converting the original floating point format to one with a smaller "range" and/or "precision."
			Projects like <u>llama.cpp</u>, <u>AutoGPTQ</u>, and <u>Ctranslate2</u> each have their strengths and weaknesses, but the
			goal is to reduce the resources needed while only suffering a "reasonable" loss in quality.</p>
			
			<p>For example, descriptions such as "Q8_0" or "8-bit" refer to the "floating point format" of "<u>int8</u>," which has
			the following range and precision:
			
		<table class="table-from-second-file" border="1">
			<tr>
				<th>Integer Data Type</th>
				<th>Range</th>
				<th>Number of Discrete Values</th>
			</tr>
			<tr>
				<td>int8</td>
				<td>-128 to 127</td>
				<td>256 (from -128 to 127)</td>
			</tr>
		</table>

			<p><b>Technically</b>, "int8" is no longer "floating"...but this primer is not intended to explain things at a university
			level...</p>
			
			<p>...you might say that the "range" and/or "precision" of this primer is only what is necessary to give a user a
			basic understanding of the concepts in order to use this program.  In other words, I have specifically chosen to use
			a lower floating point format in order to avoid the memory and compute resources required to fully research all of
			the concepts discussed in this primer...after all, we're not sending astronauts into space here!</p>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

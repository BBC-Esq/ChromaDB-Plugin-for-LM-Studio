<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }
		
		header {
			text-align: center;
			background-color: #3498db;
			color: #333;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}
		
		header a {
			color: #fff;
			text-decoration: none;
		}
		
		h2:target {
			padding-top: 275px;
			margin-top: -100px;
			display: block;
		}

		header a:hover {
			text-decoration: underline;
		}
		
		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}
		
		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}
		
		p {
			text-indent: 25px;
		}

		
		table {
            color: black;
			border-collapse: collapse;
            margin: 25px auto;
        }
		
		thead th {
			background-color: #f69784;
		}

        table, th, td {
            border: 1px solid black;
        }

        th, td {
            padding: 8px 12px;
        }

        .tiny {
            background-color: #e6f7ff;
        }

        .base {
            background-color: #b3e0ff;
        }

        .small {
            background-color: #66c2ff;
        }

        .medium {
            background-color: #3399ff;
        }

        .large {
            background-color: #0073e6;
        }
		
		code {
			background-color: #d0d0d0;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
		
		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		.table-from-second-file, .table-from-second-file th, .table-from-second-file td {
			border-collapse: collapse;
			margin: 25px auto;
			text-align: center;
			padding: 8px;
			border-bottom: 1px solid #ddd;
			color: #000; /* for th and td */
		}

		.table-from-second-file th {
			background-color: #f2f2f2;
			color: #000;
		}
		
		.table-from-second-file td {
			color: #fff; /* White color for non-header cells */
			border-bottom: 1px solid #fff;
			border-left: 1px solid #fff;
			border-right: 1px solid #fff;
			text-align: center;
		}
		
		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}
    </style>
</head>

<body>

	<header>
		<h1>Whisper Transcription</h1>
		<nav>
			<a href="#overview">Overview</a> |
			<a href="#transcribe-question">Transcribe Question</a> |
			<a href="#transcribe-file">Transcribe Audio Files</a> |
			<a href="#floating">Introduction to Floating Point Formats</a> |
			<a href="#quantization">What is Quantization?</a> |
			<a href="#available-models">Available Whisper Models and Quants</a> |
		</nav>
	</header>
	
	<main>
	
	<h2 id="overview">Overview</h2>
	
	<p><b>This program uses state-of-the-art Whisper models to:</b></p>
<ol>
    <li>Transcribe your question into the question box</li>
    <li>Transcribe an audio file to a <code>.txt</code> file that will be put into the vector database.</li>
</ol>

	<h2 id="transcribe-question">Transcribe Question</h2>
	
	<p>The <code>Record Question</code> button loads the Whisper model.  You can then speak, click the button again, and your
	question will be transcribed directly to the question box.  Previous version of this program used the
	<code>faster-whisper</code> library and included detailed settings for model name, size, quantization, and
	compute device (e.g. cpu, cuda or mps).  I've switched to the much faster <code>whisperS2A</code> library and have temporarily
	removed these settings.  Currently the <code>small.en</code> model is us by default, running in "float32," and a batch processing
	size of 16 is used.  The compute device is always "cpu" currently. I will likely add the ability to customize these settings
	in a future release.</p>
	
	<h2 id="transcribe-file">Transcribe File</h2>
	
	<p>In order to add transcriptions of audio files to the vector database you must first go to the <u>Tools Tab</u> and process
	an audio file.  You can do this multiple times, however, and each the transcription will be added to the "Create Database" tab.  Remember, you must subsequently create the vector database.</p>
	
	<p>Since switching to the <code>whisperS2A</code> library, I've simplified the settings in terms of size and quantization
	of the Whisper model to use, and the default compute device is always "cuda" or "mps" if available, and if not, "cpu."
	However, I will likely add back the ability to change these settings in the future.</p>

	<p>NOTE.  The huge speedup provided by <code>whisperS2A</code> library is primarily due to "batch processing," which can be
	controlled from the "Speed" slider bar.  The amount of processing time and resources required are directly impacted by these
	two settings.  Therefore, I highly recommend first testing your settings a single audio file of approximately 2 minutes
	before processing longer files.</p>
	
	<p>The resulting transcription is held in a "document object," which the Langchain library recognizes, prior to being put into
	the vector database.  This "document object" is saved as an actual file using the <code>pickle</code> library from the standard
	python library, but is deleted once the vector database is created.  Therefore, if you want to add the same audio transcription to multiple databases you'd need to redo the transcription or manually copy and paste the pickle file into the "Docs_for_DB" folder inbetween database runs.</p>
	
	<h2 id="Tips">Recommendations</h2>
	
	<p>Always use the large-v2 model in order to get high quality transcriptions.  In theory, you're ideally only entering a
	transcription into the vector database once and it needs to be reliably searchable.  This is in contrast to  when
	transcribing a question, which can be easily corrected within the question box.  One exception might be if you are NOT using GPU acceleration (i.e. either cuda or mps) and the "cpu" device is being used.  If you do not have a high-end cpu and/or the audio
	file is relatively long, using the large-v2 could result in very long transcription times and reducing the model size can help
	tremendously.</p>
	
	<p>After ideally choosing the large-v2 model, set the speed setting at the highest level where only VRAM is being used.  If any VRAM usage spills over into regular system RAM, it will greatly slow down the transcription process.  This is where experimenting with a 2 minute audio file first is useful, and obviously if you're not using "cuda" or "mps" then this is not a concern.</p>


        <h2 id="floating">Primer on Floating Point Formats</h2>
		
		<section>
            <img src="./float.png" alt="Floating Point">
        </section>

        <p>Running an embedding model or an LLM requires a lot of math calculations and computers don't understand
		decimals (1,2,3) like humans.  Instead, they represent numbers with a series of ones and zeros called "bits."
		In general, the more bits used used to represent a number means higher accuracy when performing math calculations, which
		means a higher quality in a model's output.  However, this also means that more memory and compute resources are needed.</p>
		
		<p>The "quality" of a model also depends on how many of the bits are "exponent" versus "fraction." The phrase
		"<u>Floating Point Format</u>" refers to both (1) the total number of bits used and (2) how many of those bits are
		"exponent" versus "fraction" bits.  The three most common floating point formats are above.  Notice that both
		<u>float16</u> and <u>bfloat16</u> use 16 bits but a differing number of "exponent" versus "fraction" bits.</p>
		
		<p>The number of "<u>exponent</u>" bits determines the "range" of numbers that can be used when performing math calculations.
		For example, <u>float32</u> uses 8 "exponent" bits, which hypothetically allows using any integer between one and
		one-hundred.  Its "range," in other words, is 1-100.  <u>Bfloat16</u> would have the same "range" because it also
		uses 8 "exponent" bits.  However, <u>float16</u> might have a "range" of 1-50  since it only uses 5 "exponent" bits.</p>

        <p></p>
		
		<p>The number of "<u>fraction</u>" bits determines how many "<u>unique values</u>" that can be used within that "range."
		For example, <u>float32</u> uses 23 "fraction" bits, which hypothetically allows it to use every whole number between 1-100
		when doing math.  <u>Bfloat16</u> only uses 7 "fraction" bits, which hypothetically only allows it to use 25 unique values
		within its range.  This is sometimes referred to as the "precision" of floating point format.</p>

        <p>Hypotheticals aside, here are the actual ranges/precisions:</p>
		
			<table class="table-from-second-file" border="1">
				<tr>
					<th>Floating Point Format</th>
					<th>Range (Approximate)</th>
					<th>Precision</th>
				</tr>
				<tr>
					<td>float32</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>6 to 9 decimal digits</td>
				</tr>
				<tr>
					<td>float16</td>
					<td>±6.1 × 10<sup>-5</sup> to ±6.5 × 10<sup>4</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
				<tr>
					<td>bfloat16</td>
					<td>±1.4 × 10<sup>-45</sup> to ±3.4 × 10<sup>38</sup></td>
					<td>3 to 4 decimal digits</td>
				</tr>
			</table>

		<p>It's important to note that "<u>range</u>" and "<u>precision</u>" both determine the "quality" of an output but in
		different ways, and different floating point formats are good for different purposes.  For example, Google (which created
		<u>bfloat16</u>), found that it was better for neural networks while <u>float16</u> was better for "scientific" calculations.</p>
		
		<p>You can see the floating point format of the various embedding models used inthis program by looking at the
		<code>config.json</code> file for each model.  All of the Whisper models used in this program were created with
		<u>float32</u> and you can experiment with the various quantizations I've done for each size of model.</p>
		
        <section>
            <h2 id="quantization">What is Quantization?</h2>
			
            <p>"<u>Quantization</u>" means converting the original floating point format to one with a smaller "range" and/or "precision."
			Projects like <u>llama.cpp</u>, <u>AutoGPTQ</u>, and <u>Ctranslate2</u> each have their strengths and weaknesses, but the
			goal is to reduce the resources needed while only suffering a "reasonable" loss in quality.</p>
			
			<p>For example, descriptions such as "Q8_0" or "8-bit" refer to the "floating point format" of "<u>int8</u>," which has
			the following range and precision:
			
		<table class="table-from-second-file" border="1">
			<tr>
				<th>Integer Data Type</th>
				<th>Range</th>
				<th>Number of Discrete Values</th>
			</tr>
			<tr>
				<td>int8</td>
				<td>-128 to 127</td>
				<td>256 (from -128 to 127)</td>
			</tr>
		</table>

			<p><b>Technically</b>, "int8" is no longer "floating"...but this primer is not intended to explain things at a university
			level...</p>
			
			<p>...you might say that the "range" and/or "precision" of this primer is only what is necessary to give a user a
			basic understanding of the concepts in order to use this program.  In other words, I have specifically chosen to use
			a lower floating point format in order to avoid the memory and compute resources required to fully research all of
			the concepts discussed in this primer...after all, we're not sending astronauts into space here!</p>

	<h2 id="available-models">Whisper Sizes and Quants</h2>
	
	<table>
        <thead>
            <tr>
                <th>Quantization</th>
                <th>Size on Disk</th>
            </tr>
        </thead>
        <tbody>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_bfloat16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float16</td>
                <td>42.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_bfloat16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float16</td>
                <td>43.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-int8_float32</td>
                <td>45.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-int8_float32</td>
                <td>45.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_bfloat16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float16</td>
                <td>78.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_bfloat16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float16</td>
                <td>78.7 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-bfloat16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float16</td>
                <td>78.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-bfloat16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float16</td>
                <td>79.1 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-int8_float32</td>
                <td>82.4 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-int8_float32</td>
                <td>82.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-bfloat16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float16</td>
                <td>148.5 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-bfloat16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float16</td>
                <td>148.8 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny.en-ct2-float32</td>
                <td>154.4 MB</td>
            </tr>
            <tr class="tiny">
                <td>whisper-tiny-ct2-float32</td>
                <td>154.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_bfloat16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float16</td>
                <td>249.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_bfloat16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float16</td>
                <td>250.2 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-int8_float32</td>
                <td>257.3 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-int8_float32</td>
                <td>257.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base.en-ct2-float32</td>
                <td>293.7 MB</td>
            </tr>
            <tr class="base">
                <td>whisper-base-ct2-float32</td>
                <td>294.0 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-bfloat16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float16</td>
                <td>486.8 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-bfloat16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float16</td>
                <td>487.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_bfloat16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float16</td>
                <td>775.8 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_bfloat16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float16</td>
                <td>776.1 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-int8_float32</td>
                <td>788.2 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-int8_float32</td>
                <td>788.5 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small.en-ct2-float32</td>
                <td>970.4 MB</td>
            </tr>
            <tr class="small">
                <td>whisper-small-ct2-float32</td>
                <td>970.7 MB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-bfloat16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float16</td>
                <td>1.5 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_bfloat16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float16</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-int8_float32</td>
                <td>1.6 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium.en-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="medium">
                <td>whisper-medium-ct2-float32</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-bfloat16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float16</td>
                <td>3.1 GB</td>
            </tr>
            <tr class="large">
                <td>whisper-large-v2-ct2-float32</td>
                <td>6.2 GB</td>
            </tr>
        </tbody>
    </table>
</div>

</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>

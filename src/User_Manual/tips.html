<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tips</title>
	<style>
		body {
			font-family: Arial, sans-serif;
			line-height: 1.6;
			margin: 0;
			padding: 0;
			background-color: #161b22;
			color: #d0d0d0;
		}

		header {
			text-align: center;
			background-color: #3498db;
			color: #fff;
			padding: 20px;
			position: sticky;
			top: 0;
			z-index: 999;
		}

		main {
			max-width: 800px;
			margin: 0 auto;
			padding: 20px;
		}

		img {
			display: block;
			margin: 0 auto;
			max-width: 100%;
			height: auto;
		}

		h1 {
		  color: #333;
		}

		h2 {
		  color: #f0f0f0;
		  text-align: center;
		}

		p {
			text-indent: 35px;
		}

		table {
			border-collapse: collapse;
			width: 80%;
			margin: 50px auto;
		}

		th, td {
			text-align: left;
			padding: 8px;
			border-bottom: 1px solid #ddd;
		}

		th {
			background-color: #f2f2f2;
			color: #000;
		}

		footer {
			text-align: center;
			background-color: #333;
			color: #fff;
			padding: 10px;
		}
		
		code {
			background-color: #f9f9f9;
			border-radius: 3px;
			padding: 2px 3px;
			font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
			color: #333;
		}
	</style>

</head>

<body>
    <header>
        <h1>Usage Tips</h1>
    </header>

    <main>

        <section>
		
		<h2 style="color: #f0f0f0;" align="center">Database Searching</h2>
		
		<p>As of release 3.3 there are powerful search options you must be aware of to get the best results; specifically, the
		<code>contexts</code>, <code>similarity</code>, and <code>search filter</code> settings located within the Settings Tab.
		It's crucial to understand how these interact.</p>

		<p><code>Similarity</code> refers to how relevant a chunk must be to a user's query before it's eligible to be returned.
		A setting of "1" indicates a perfect result, for example, and should NOT be used because there is never a perfect result.
		A good starting point is .3 or .4 and adjust accordingly based on the quality of the chunks you're getting.  It's also
		possible to set this to zero (0) and instead rely on the following two settings in curating the chunks you get.</p>
		
		<p><code>Contexts</code> refers to the top "X" relevant results where "X" is the number of contexts you specify.  For
		example, if you specify eight (8) contexts then it will most likely return the eight (8) most relevant contexts.  I say
		"most likely" because there is a comment in the version of Langchain that this program uses, stating that this needs to be
		doublechecked.</p>
		
		<p><code>Contexts</code> is inherently limited by <code>similarity</code>.  For example, if there are no chunks that meet
		the similarity threshold, no chunks will be returned even if you were to request the top 100 (to use an extreme example)
		most relevant contexts.  A good analogy is to think of <code>similarity</code> as creating a pool of all chunks that meet
		the similarity threshold and <code>contexts</code> as returning the top "X" most relevant results from that pool.</p>
		
		<p><code>Search Filter</code> takes this one step further and should be used with caution.  It is NOT part of the Langchain
		library but is rather a custom filter applied afterwards.  It operates as follows:  After <code>similarity</code> and
		<code>contexts</code> are applied, it explicitly excludes any chunks/contexts that do not include the specified term.
		In other words, each chunk must contain "verbatim" the characters constituting the search term, but the search term itself
		is NOT case-sensitive.</p>
		
		<p>For example, if you specify a search filter of "child", chunks that have similar terms like "children" or "child's"
		WOULD BE EXCLUDED because they don't match the exact term "child."  With that being said, it is case sensitive and therefore
		terms like "Child" or "cHILd" (for that matter) would satisfy the filter; hence not be excluded.</p>
		
		<p><code>Search Filter</code> is powerful and should be used with caution.  It should be used with an extremely
		low <code>similarity</code> and high <code>contexts</code> setting.  For example, let's say that within the database there
		are a grand total of 100 chunks that contain the term "child..." let's further assume that you set <code>similarity</code>
		to .8 but only 10 of the 100 chunks meet this threshold...let's further assume that you want the top 20
		<code>contexts</code> that include the term "child."  However, you're only going to get 10 chunks because the
		<code>similarity</code> setting sets a relevance threshold that a chunk must meet to even be considered as being retrieved.</p>
		
		<p>If you are reasonably confident that one or more chunks that are relevant contain your specified term, the better strategy
		is to set <code>similarity</code> so no chunks are excluded and <code>contexts</code> very high, which you can then adjust as needed.  Remember, <code>similarity</code> assesses the relevance of a chunk in its entirety while <code>search filter</code>
		merely asks whether a term is in a specific chunk or not...very different approaches, but when used properly, can lead to
		very efficient results.</p>
		
		<p>For example, let's hypothetically set <code>similarity</code> to .3, <code>contexts</code> to 1,000, and the
		<code>search filter</code> "preliminary".  Hypothetically, there's 500,000 chunks in the database.  5,000 meet the similarity
		threshold that I set, 1,000 of the most relevant chunks are returned...finally, only 25 of those chunks contain "preliminary;"
		therefore, onlyk 25 chunks are ultimately considered.</p>
		
		<h2 style="color: #f0f0f0;" align="center">Free up VRAM on Your System</h2>
		
		<p>Unplug any secondary monitors from the GPU and plug them into the graphics ports coming from your motherboard instead.
		This forces your monitors to only use system memory and not VRAM.  However, your CPU must have "integrated graphics"
		for this to work.  For example, Intel CPUs that have the letter "F" at the end do not contain integrated graphics.</p>
		
		<p>Please note, however, that some motherboards automatically disable the graphics adapters if a GPU is installed.  The
		motherboard manufacturer basically assumes that all monitors will be plugged into the GPU.  You can change
		this behavior by entering BIOS and re-enable the graphics ports coming from your motherboard.  Check your motherboard's
		documentation on how to do this because each BIOS is slightly different.</p>
		
		<h2 style="color: #f0f0f0;" align="left">Efficiently use VRAM</h2>
		
		<p>The most important thing is to load the entire LLM used in LM Studio into VRAM (not system RAM) when interacting
		with the LLM.  Even if you load 99% of the "layers" into VRAM, you will NOT get 99% of the speed compared to
		the entire model being in VRAM.</p>
		
		<p>Likewise, when you create the vector database you want to ensure that the entire embedding model is loaded into VRAM.
		If you don't have sufficient VRAM to have both the LLM within LM Studio and the embedding model in VRAM, this necessitates
		"ejecting" the LLM within LM Studio prior to creating the vector database.  After the database is created you can simply
		reload the LLM within LM Studio.</p>
		
		<p>Do not use GPU-acceleration when querying the vector database.  Querying the database requires 1,000x LESS
		(no exaggeration) compute power compared to creating the database.  Therefore, you can easily query the embedding model
		using your CPU (and hence not use VRAM).  This will ensure that the LLM within LM Studio is entirely within VRAM.</p>
		
		<p>If you don't have a GPU (and can't use VRAM) you're forced to manager your system memory.</p>
		
		<h2 style="color: #f0f0f0;" align="center">Select an Appropriate Embedding Model</h2>
		
		<p>The new Embedding Models portion of this User Guide has a thorough explanation.</p>
		
		<h2 style="color: #f0f0f0;" align="center">Select an Appropriate Whisper Model</h2>
		
		<p> The Transcribe portion of this User Guide has a more in-depth discussion.</p>
		
		<h2 style="color: #f0f0f0;" align="center">Ensure Sufficient Context Length for the LLM</h2>
		
		<p>See the "Settings" portion of this User Manual for more information.  However, in general each embedding model has
		it's own unique token limit (referred to as "max sequence"), which can be seen by clicking the "Download" embedding
		model button.</p>
		
		<h2 style="color: #f0f0f0;" align="center">Quality Transcriptions</h2>
		
		<p>It's generally recommended to use the large-v2 model for transcribing an audio file to a <code>.txt</code> file to
		be put into the vector database.  You can get away with using a smaller model when transcribing your query and can easily
		correct any errors in the question box, but you want a high-quality transcription when transcribing a file.  If you're
		short on VRAM, this necessitates ejecting the LLM from within LM Studio before transcribing a file so that the entire
		Whisper model will use VRAM.</p>
		
		<p>The Whisper model will be removed from VRAM immediately after transcribing a file, at which point you can simply reload
		the LLM within LM Studio.</p>

	</main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>
